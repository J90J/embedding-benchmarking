{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mini Project 1 - Part 1_Jens Jung: Word Embeddings in Colab\n"
      ],
      "metadata": {
        "id": "wyay3hLq0D3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries\n",
        "!pip install sentence-transformers openai gdown numpy pandas matplotlib\n",
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "import pickle\n",
        "import os\n",
        "import gdown\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "# API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"INSERT_YOUR_API_KEY_HERE\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6QrNpcy0X0A",
        "outputId": "4006bb8a-e531-48b3-a1c2-33fa45613d85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.15.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Helper Functions\n"
      ],
      "metadata": {
        "id": "Md0MyRGr04wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_id_gdrive(model_type):\n",
        "    \"\"\"\n",
        "    Returns the Google Drive IDs for the specified GloVe model type.\n",
        "    \"\"\"\n",
        "    if model_type == \"25d\":\n",
        "        word_index_id = \"13qMXs3-oB9C6kfSRMwbAtzda9xuAUtt8\"\n",
        "        embeddings_id = \"1-RXcfBvWyE-Av3ZHLcyJVsps0RYRRr_2\"\n",
        "    elif model_type == \"50d\":\n",
        "        embeddings_id = \"1DBaVpJsitQ1qxtUvV1Kz7ThDc3az16kZ\"\n",
        "        word_index_id = \"1rB4ksHyHZ9skes-fJHMa2Z8J1Qa7awQ9\"\n",
        "    elif model_type == \"100d\":\n",
        "        # Ids swapped\n",
        "        word_index_id = \"1-oWV0LqG3fmrozRZ7WB1jzeTJHRUI3mq\"\n",
        "        embeddings_id = \"1SRHfX130_6Znz7zbdfqboKosz-PfNvNp\"\n",
        "\n",
        "    return word_index_id, embeddings_id\n",
        "def download_glove_embeddings_gdrive(model_type):\n",
        "    \"\"\"\n",
        "    Downloads GloVe embeddings from Google Drive.\n",
        "    \"\"\"\n",
        "    word_index_id, embeddings_id = get_model_id_gdrive(model_type)\n",
        "    embeddings_temp = \"embeddings_\" + str(model_type) + \"_temp.npy\"\n",
        "    word_index_temp = \"word_index_dict_\" + str(model_type) + \"_temp.pkl\"\n",
        "    if not os.path.exists(word_index_temp):\n",
        "        print(f\"Downloading word index for {model_type}...\")\n",
        "        gdown.download(id=word_index_id, output=word_index_temp, quiet=False)\n",
        "\n",
        "    if not os.path.exists(embeddings_temp):\n",
        "        print(f\"Downloading embeddings for {model_type}...\")\n",
        "        gdown.download(id=embeddings_id, output=embeddings_temp, quiet=False)\n",
        "def load_glove_embeddings_gdrive(model_type):\n",
        "    \"\"\"\n",
        "    Loads the downloaded GloVe embeddings.\n",
        "    \"\"\"\n",
        "    word_index_temp = \"word_index_dict_\" + str(model_type) + \"_temp.pkl\"\n",
        "    embeddings_temp = \"embeddings_\" + str(model_type) + \"_temp.npy\"\n",
        "\n",
        "    word_index_dict = pickle.load(open(word_index_temp, \"rb\"), encoding=\"latin\")\n",
        "    embeddings = np.load(embeddings_temp)\n",
        "\n",
        "    return word_index_dict, embeddings\n",
        "def get_openai_embeddings(sentence, model_name=\"text-embedding-3-small\"):\n",
        "    \"\"\"\n",
        "    Get OpenAI embeddings. Returns zero vector if API call fails.\n",
        "    \"\"\"\n",
        "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "    try:\n",
        "        response = client.embeddings.create(input=sentence, model=model_name)\n",
        "        return np.array(response.data[0].embedding)\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting OpenAI embeddings: {e}\")\n",
        "        dim = 3072 if model_name == \"text-embedding-3-large\" else 1536\n",
        "        return np.zeros(dim)\n",
        "# Initialize Sentence Transformer\n",
        "st_model_mini = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "def get_sentence_transformer_embeddings(sentence, model_name=\"all-MiniLM-L6-v2\"):\n",
        "    \"\"\"\n",
        "    Get Sentence Transformer embeddings.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if model_name == \"all-MiniLM-L6-v2\":\n",
        "            return st_model_mini.encode(sentence)\n",
        "        else:\n",
        "            temp_model = SentenceTransformer(model_name)\n",
        "            return temp_model.encode(sentence)\n",
        "    except:\n",
        "        return np.zeros(384)\n",
        "def get_glove_embeddings(word, word_index_dict, embeddings, model_type):\n",
        "    \"\"\"\n",
        "    Get embedding for a single word from GloVe.\n",
        "    \"\"\"\n",
        "    if word.lower() in word_index_dict:\n",
        "        return embeddings[word_index_dict[word.lower()]]\n",
        "    else:\n",
        "        return np.zeros(int(model_type.split(\"d\")[0]))"
      ],
      "metadata": {
        "id": "veMTSqok1BeI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Tasks Implementation\n"
      ],
      "metadata": {
        "id": "juKpEFKk1vz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(x, y):\n",
        "    \"\"\"\n",
        "    Exponentiated cosine similarity\n",
        "    1. Compute cosine similarity\n",
        "    2. Exponentiate cosine similarity\n",
        "    3. Return exponentiated cosine similarity\n",
        "    \"\"\"\n",
        "    # No division by zero\n",
        "    norm_x = la.norm(x)\n",
        "    norm_y = la.norm(y)\n",
        "\n",
        "    if norm_x == 0 or norm_y == 0:\n",
        "        return 0.0\n",
        "\n",
        "    dot_product = np.dot(x, y)\n",
        "    cos_sim = dot_product / (norm_x * norm_y)\n",
        "\n",
        "    return np.exp(cos_sim)"
      ],
      "metadata": {
        "id": "Oev72sTx14W4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task II: Averaged GloVe Embeddings\n",
        "We implement the function to calculate the sentence embedding by averaging the embeddings of its constituent words."
      ],
      "metadata": {
        "id": "dWgR383X187k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def averaged_glove_embeddings_gdrive(sentence, word_index_dict, embeddings, model_type=\"50d\"):\n",
        "    \"\"\"\n",
        "    Get averaged glove embeddings for a sentence\n",
        "    \"\"\"\n",
        "    embedding_dim = int(model_type.split(\"d\")[0])\n",
        "\n",
        "    words = sentence.split()\n",
        "    if not words:\n",
        "        return np.zeros(embedding_dim)\n",
        "\n",
        "    sum_embedding = np.zeros(embedding_dim)\n",
        "\n",
        "    for word in words:\n",
        "        word_embed = get_glove_embeddings(word, word_index_dict, embeddings, model_type)\n",
        "        sum_embedding += word_embed\n",
        "\n",
        "    avg_embedding = sum_embedding / len(words)\n",
        "    return avg_embedding"
      ],
      "metadata": {
        "id": "OtMBNrqh2DTp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task III. Sorted Cosine Similarity\n"
      ],
      "metadata": {
        "id": "2Gfy9BBQ2b5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sorted_cosine_similarity(input_sentence, categories_str, embeddings_metadata):\n",
        "    \"\"\"\n",
        "    Get sorted cosine similarity between input sentence and categories.\n",
        "\n",
        "    Args:\n",
        "        input_sentence: The search query/sentence.\n",
        "        categories_str: Space-separated string of categories (e.g., \"Flowers Colors Cars\").\n",
        "        embeddings_metadata: Dict with model info.\n",
        "    \"\"\"\n",
        "    categories = categories_str.split(\" \")\n",
        "    scores = []\n",
        "\n",
        "    # 1. Calculate Input Sentence\n",
        "\n",
        "    if embeddings_metadata[\"embedding_model\"] == \"glove\":\n",
        "        word_index = embeddings_metadata[\"word_index_dict\"]\n",
        "        embeds = embeddings_metadata[\"embeddings\"]\n",
        "        m_type = embeddings_metadata[\"model_type\"]\n",
        "\n",
        "        # Input Embedding\n",
        "        input_vec = averaged_glove_embeddings_gdrive(input_sentence, word_index, embeds, m_type)\n",
        "\n",
        "        # Category Embeddings & Similarity\n",
        "        for i, cat in enumerate(categories):\n",
        "            cat_vec = averaged_glove_embeddings_gdrive(cat, word_index, embeds, m_type)\n",
        "            score = cosine_similarity(input_vec, cat_vec)\n",
        "            scores.append((i, score))\n",
        "    elif embeddings_metadata[\"embedding_model\"] == \"openai\":\n",
        "        model_name = embeddings_metadata[\"model_name\"]\n",
        "\n",
        "        # Input Embedding\n",
        "        input_vec = get_openai_embeddings(input_sentence, model_name)\n",
        "\n",
        "        # Category Embeddings & Similarity\n",
        "        for i, cat in enumerate(categories):\n",
        "            cat_vec = get_openai_embeddings(cat, model_name)\n",
        "            score = cosine_similarity(input_vec, cat_vec)\n",
        "            scores.append((i, score))\n",
        "    else: # Transformers\n",
        "        model_name = embeddings_metadata[\"model_name\"]\n",
        "\n",
        "        # Input Embedding\n",
        "        input_vec = get_sentence_transformer_embeddings(input_sentence, model_name)\n",
        "\n",
        "        # Category Embeddings & Similarity\n",
        "        for i, cat in enumerate(categories):\n",
        "            cat_vec = get_sentence_transformer_embeddings(cat, model_name)\n",
        "            score = cosine_similarity(input_vec, cat_vec)\n",
        "            scores.append((i, score))\n",
        "    # 2. Sort results by score (descending)\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return scores"
      ],
      "metadata": {
        "id": "fDS4QvuY2gNZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Execution and Visualization\n"
      ],
      "metadata": {
        "id": "FADIVbwr2lsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pie_chart(sorted_scores, categories_str, title):\n",
        "    categories = categories_str.split(\" \")\n",
        "\n",
        "    labels = [categories[idx] for idx, score in sorted_scores]\n",
        "    sizes = [score for idx, score in sorted_scores]\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "def run_demo(categories_input, text_search_input, glove_dim=\"50d\"):\n",
        "    print(f\"--- Running Demo ---\")\n",
        "    print(f\"Categories: {categories_input}\")\n",
        "    print(f\"Input: '{text_search_input}'\")\n",
        "    print(f\"GloVe Model: {glove_dim}\")\n",
        "\n",
        "    # 1. Setup Data\n",
        "    download_glove_embeddings_gdrive(glove_dim)\n",
        "    word_index, embeddings = load_glove_embeddings_gdrive(glove_dim)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # 2. Run Models\n",
        "\n",
        "    # GloVe\n",
        "    print(\"\\nCalculating GloVe...\")\n",
        "    meta_glove = {\n",
        "        \"embedding_model\": \"glove\",\n",
        "        \"word_index_dict\": word_index,\n",
        "        \"embeddings\": embeddings,\n",
        "        \"model_type\": glove_dim\n",
        "    }\n",
        "    res_glove = get_sorted_cosine_similarity(text_search_input, categories_input, meta_glove)\n",
        "    results[\"GloVe\"] = res_glove\n",
        "\n",
        "    # Sentence Transformer\n",
        "    print(\"Calculating Sentence Transformer...\")\n",
        "    meta_trans = {\n",
        "        \"embedding_model\": \"transformers\",\n",
        "        \"model_name\": \"all-MiniLM-L6-v2\"\n",
        "    }\n",
        "    res_trans = get_sorted_cosine_similarity(text_search_input, categories_input, meta_trans)\n",
        "    results[\"SentenceTransformer\"] = res_trans\n",
        "\n",
        "    # OpenAI Small\n",
        "    print(\"Calculating OpenAI Small...\")\n",
        "    meta_oa_small = {\n",
        "        \"embedding_model\": \"openai\",\n",
        "        \"model_name\": \"text-embedding-3-small\"\n",
        "    }\n",
        "    res_oa_small = get_sorted_cosine_similarity(text_search_input, categories_input, meta_oa_small)\n",
        "    results[\"OpenAI_Small\"] = res_oa_small\n",
        "\n",
        "    # OpenAI Large\n",
        "    print(\"Calculating OpenAI Large...\")\n",
        "    meta_oa_large = {\n",
        "        \"embedding_model\": \"openai\",\n",
        "        \"model_name\": \"text-embedding-3-large\"\n",
        "    }\n",
        "    res_oa_large = get_sorted_cosine_similarity(text_search_input, categories_input, meta_oa_large)\n",
        "    results[\"OpenAI_Large\"] = res_oa_large\n",
        "\n",
        "    # 3. Display Results\n",
        "    categories_list = categories_input.split(\" \")\n",
        "\n",
        "    # Create Comparison Table\n",
        "    data = []\n",
        "    for model_name, res in results.items():\n",
        "        top_idx, top_score = res[0]\n",
        "        data.append({\n",
        "            \"Model\": model_name,\n",
        "            \"Top Category\": categories_list[top_idx],\n",
        "            \"Confidence\": f\"{top_score:.4f}\"\n",
        "        })\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"\\n--- Summary Results ---\")\n",
        "    print(df)\n",
        "    return results\n",
        "# --- TEST 1: Basic Test ---\n",
        "run_demo(\"Flowers Colors Cars Weather Food\", \"Roses are red, trucks are blue\", glove_dim=\"50d\")\n",
        "# --- TEST 2: Sentiment ---\n",
        "print(\"\\n\\n--- Sentiment Test 1 ---\")\n",
        "run_demo(\"Positive Negative\", \"The movie was upsetting\", glove_dim=\"50d\")\n",
        "# Input 2: \"This is terrible\"\n",
        "print(\"\\n\\n--- Sentiment Test 2 ---\")\n",
        "run_demo(\"Positive Negative\", \"This is terrible\", glove_dim=\"50d\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WerAERLX2qpo",
        "outputId": "d17505ff-74ba-4959-d9fd-89b1ceb2d9e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Demo ---\n",
            "Categories: Flowers Colors Cars Weather Food\n",
            "Input: 'Roses are red, trucks are blue'\n",
            "GloVe Model: 50d\n",
            "Downloading word index for 50d...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rB4ksHyHZ9skes-fJHMa2Z8J1Qa7awQ9\n",
            "To: /content/word_index_dict_50d_temp.pkl\n",
            "100%|██████████| 60.3M/60.3M [00:00<00:00, 99.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading embeddings for 50d...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1DBaVpJsitQ1qxtUvV1Kz7ThDc3az16kZ\n",
            "From (redirected): https://drive.google.com/uc?id=1DBaVpJsitQ1qxtUvV1Kz7ThDc3az16kZ&confirm=t&uuid=6a7af07b-085c-4238-a274-a8bad1911e50\n",
            "To: /content/embeddings_50d_temp.npy\n",
            "100%|██████████| 477M/477M [00:05<00:00, 93.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating GloVe...\n",
            "Calculating Sentence Transformer...\n",
            "Calculating OpenAI Small...\n",
            "Calculating OpenAI Large...\n",
            "\n",
            "--- Summary Results ---\n",
            "                 Model Top Category Confidence\n",
            "0                GloVe       Colors     2.1371\n",
            "1  SentenceTransformer      Flowers     1.6905\n",
            "2         OpenAI_Small      Flowers     1.4881\n",
            "3         OpenAI_Large      Flowers     1.4724\n",
            "\n",
            "\n",
            "--- Sentiment Test 1 ---\n",
            "--- Running Demo ---\n",
            "Categories: Positive Negative\n",
            "Input: 'The movie was upsetting'\n",
            "GloVe Model: 50d\n",
            "\n",
            "Calculating GloVe...\n",
            "Calculating Sentence Transformer...\n",
            "Calculating OpenAI Small...\n",
            "Calculating OpenAI Large...\n",
            "\n",
            "--- Summary Results ---\n",
            "                 Model Top Category Confidence\n",
            "0                GloVe     Positive     1.8110\n",
            "1  SentenceTransformer     Negative     1.1408\n",
            "2         OpenAI_Small     Negative     1.2863\n",
            "3         OpenAI_Large     Negative     1.2693\n",
            "\n",
            "\n",
            "--- Sentiment Test 2 ---\n",
            "--- Running Demo ---\n",
            "Categories: Positive Negative\n",
            "Input: 'This is terrible'\n",
            "GloVe Model: 50d\n",
            "\n",
            "Calculating GloVe...\n",
            "Calculating Sentence Transformer...\n",
            "Calculating OpenAI Small...\n",
            "Calculating OpenAI Large...\n",
            "\n",
            "--- Summary Results ---\n",
            "                 Model Top Category Confidence\n",
            "0                GloVe     Positive     1.9140\n",
            "1  SentenceTransformer     Negative     1.3541\n",
            "2         OpenAI_Small     Negative     1.3417\n",
            "3         OpenAI_Large     Negative     1.3204\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GloVe': [(0, np.float64(1.9139887701630862)),\n",
              "  (1, np.float64(1.7827631592375468))],\n",
              " 'SentenceTransformer': [(1, np.float32(1.3540865)),\n",
              "  (0, np.float32(1.2986877))],\n",
              " 'OpenAI_Small': [(1, np.float64(1.3417168345735198)),\n",
              "  (0, np.float64(1.183129484034134))],\n",
              " 'OpenAI_Large': [(1, np.float64(1.3203831599227975)),\n",
              "  (0, np.float64(1.19677959468169))]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Part C: Real-World Applications (Word Order Experiment)\n",
        "Here we perform the experiment described in Part C of the README. We use the categories \"cinema hotel restaurant\" and test two shuffled sentences to see if the model classification changes."
      ],
      "metadata": {
        "id": "i98SE4ra3QK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_part_c_experiment():\n",
        "    categories = \"cinema hotel restaurant\"\n",
        "\n",
        "    # Example Pair 1\n",
        "\n",
        "    s1 = \"cinema hotel restaurant\"\n",
        "    s2 = \"hotel restaurant cinema\"\n",
        "\n",
        "    print(\"\\n\\n=== Part C: Word Order Experiment ===\")\n",
        "    print(f\"Categories: {categories}\")\n",
        "\n",
        "    print(f\"\\nDistorted Sentence 1: '{s1}'\")\n",
        "    run_demo(categories, s1, glove_dim=\"50d\")\n",
        "\n",
        "    print(f\"\\nDistorted Sentence 2: '{s2}'\")\n",
        "    run_demo(categories, s2, glove_dim=\"50d\")\n",
        "# Run the experiment\n",
        "run_part_c_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2FDyWxP3UkK",
        "outputId": "83b5ccd5-7a7e-4c4f-939e-c693175c7905"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=== Part C: Word Order Experiment ===\n",
            "Categories: cinema hotel restaurant\n",
            "\n",
            "Distorted Sentence 1: 'cinema hotel restaurant'\n",
            "--- Running Demo ---\n",
            "Categories: cinema hotel restaurant\n",
            "Input: 'cinema hotel restaurant'\n",
            "GloVe Model: 50d\n",
            "\n",
            "Calculating GloVe...\n",
            "Calculating Sentence Transformer...\n",
            "Calculating OpenAI Small...\n",
            "Calculating OpenAI Large...\n",
            "\n",
            "--- Summary Results ---\n",
            "                 Model Top Category Confidence\n",
            "0                GloVe        hotel     2.5466\n",
            "1  SentenceTransformer        hotel     2.0844\n",
            "2         OpenAI_Small       cinema     2.0342\n",
            "3         OpenAI_Large       cinema     1.9845\n",
            "\n",
            "Distorted Sentence 2: 'hotel restaurant cinema'\n",
            "--- Running Demo ---\n",
            "Categories: cinema hotel restaurant\n",
            "Input: 'hotel restaurant cinema'\n",
            "GloVe Model: 50d\n",
            "\n",
            "Calculating GloVe...\n",
            "Calculating Sentence Transformer...\n",
            "Calculating OpenAI Small...\n",
            "Calculating OpenAI Large...\n",
            "\n",
            "--- Summary Results ---\n",
            "                 Model Top Category Confidence\n",
            "0                GloVe        hotel     2.5466\n",
            "1  SentenceTransformer        hotel     2.0510\n",
            "2         OpenAI_Small        hotel     1.8450\n",
            "3         OpenAI_Large        hotel     1.9064\n"
          ]
        }
      ]
    }
  ]
}